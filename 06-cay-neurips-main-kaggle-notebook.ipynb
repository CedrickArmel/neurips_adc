{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9644542,"sourceType":"datasetVersion","datasetId":5889896}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-21T12:24:56.380461Z","iopub.execute_input":"2024-10-21T12:24:56.381044Z","iopub.status.idle":"2024-10-21T12:24:56.391331Z","shell.execute_reply.started":"2024-10-21T12:24:56.380996Z","shell.execute_reply":"2024-10-21T12:24:56.390126Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"/kaggle/input/neurips-adc-challenge-2024-calibrated-tfrecord/primary-neurips-dataset-20241015205628-c1d1f1m1b30.tfrecords\n","output_type":"stream"}]},{"cell_type":"code","source":"primary_dataset = tf.data.TFRecordDataset(\n    \"/kaggle/input/neurips-adc-challenge-2024-calibrated-tfrecord/primary-neurips-dataset-20241015205628-c1d1f1m1b30.tfrecords\")","metadata":{"execution":{"iopub.status.busy":"2024-10-21T11:29:39.291434Z","iopub.execute_input":"2024-10-21T11:29:39.291903Z","iopub.status.idle":"2024-10-21T11:29:39.374395Z","shell.execute_reply.started":"2024-10-21T11:29:39.291862Z","shell.execute_reply":"2024-10-21T11:29:39.373341Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Decode`tf.train.Examples` in the `TFRecord`s","metadata":{}},{"cell_type":"code","source":"def decode_fn(proto):\n    features_formats = {\n        \"id\": tf.io.FixedLenFeature([], tf.int64),\n        \"airs\": tf.io.FixedLenFeature([], tf.string),\n        \"fgs\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string),\n    }\n    example = tf.io.parse_single_example(proto, features_formats)\n    pid = example[\"id\"]\n    airs = tf.io.parse_tensor(example[\"airs\"], tf.float64)\n    fgs = tf.io.parse_tensor(example[\"fgs\"], tf.float64)\n    target = tf.io.parse_tensor(example[\"target\"], tf.float64)\n    return pid, airs, fgs, target","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:12:57.693207Z","iopub.execute_input":"2024-10-21T12:12:57.693692Z","iopub.status.idle":"2024-10-21T12:12:57.702432Z","shell.execute_reply.started":"2024-10-21T12:12:57.693647Z","shell.execute_reply":"2024-10-21T12:12:57.701125Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"def concatenate_signals(proto):\n    pid, airs, fgs, target = decode_fn(proto)\n    signal = np.concatenate(\n        [airs[:,:,1:,:].numpy(), fgs.numpy().sum(axis=2)[:,:, np.newaxis,:]], axis=2\n    )\n    signal = tf.convert_to_tensor(signal)\n    return pid, signal, target","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:13:00.490170Z","iopub.execute_input":"2024-10-21T12:13:00.490693Z","iopub.status.idle":"2024-10-21T12:13:00.498042Z","shell.execute_reply.started":"2024-10-21T12:13:00.490631Z","shell.execute_reply":"2024-10-21T12:13:00.496858Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"dataset = primary_dataset.prefetch(\n    buffer_size=tf.data.AUTOTUNE).map(lambda example: tf.py_function(\n    func=concatenate_signals, inp=[example],\n    Tout=[\n        tf.TensorSpec(shape=None, dtype=tf.int64),\n        tf.TensorSpec(shape=None, dtype=tf.float64),\n        tf.TensorSpec(shape=None, dtype=tf.float64)\n    ]))","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:13:03.399544Z","iopub.execute_input":"2024-10-21T12:13:03.399952Z","iopub.status.idle":"2024-10-21T12:13:03.419617Z","shell.execute_reply.started":"2024-10-21T12:13:03.399915Z","shell.execute_reply":"2024-10-21T12:13:03.418369Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"np_signal_dataset = None\nnp_target_dataset = None\nfor obs in iter(dataset):\n    try:\n        if np_signal_dataset is None:\n            np_signal_dataset = obs[1].numpy()\n            np_target_dataset = obs[2].numpy()\n        else:\n            np_signal_dataset = np.concatenate([np_signal_dataset, obs[1].numpy()])\n            np_target_dataset = np.concatenate([np_target_dataset, obs[2].numpy()])\n    except ValueError:\n        pass","metadata":{"execution":{"iopub.status.busy":"2024-10-21T14:29:52.964422Z","iopub.execute_input":"2024-10-21T14:29:52.965267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}